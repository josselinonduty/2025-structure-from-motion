{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Structure from Motion (SfM) Notebook\n",
        "\n",
        "This notebook demonstrates how to generate a 3D point cloud from a set of images using Structure from Motion (SfM) techniques.\n",
        "We'll use OpenCV for feature extraction, matching, and triangulation.\n",
        "Ensure you have the necessary images in the specified directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Set paths\n",
        "data_in = \"data\"\n",
        "data_set = \"globe\"\n",
        "data_out = \"out\"\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(data_out, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Feature Extraction and Matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load images\n",
        "image_paths = sorted(glob.glob(os.path.join(data_in, data_set, \"*.JPG\")))\n",
        "images = [cv2.imread(img_path, cv2.IMREAD_COLOR_RGB) for img_path in image_paths]\n",
        "\n",
        "# Initialize SIFT detector\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "# Extract features and match them\n",
        "keypoints = []\n",
        "descriptors = []\n",
        "for img in images:\n",
        "    kp, des = sift.detectAndCompute(img, None)\n",
        "    keypoints.append(kp)\n",
        "    descriptors.append(des)\n",
        "\n",
        "# Match features between consecutive images\n",
        "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "matches = []\n",
        "for i in range(len(images) - 1):\n",
        "    matches.append(bf.match(descriptors[i], descriptors[i + 1]))\n",
        "\n",
        "# Sort matches by distance\n",
        "matches = [sorted(m, key=lambda x: x.distance) for m in matches]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23618eec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot matches\n",
        "for i in range(3):\n",
        "    img_i = cv2.drawMatches(\n",
        "        images[i],\n",
        "        keypoints[i],\n",
        "        images[i + 1],\n",
        "        keypoints[i + 1],\n",
        "        matches[i],\n",
        "        None,\n",
        "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
        "    )\n",
        "\n",
        "    plt.imshow(img_i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec523a9",
      "metadata": {},
      "source": [
        "## Step 2: Eliminate Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c15b67d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove outliers from matches using cv2.findHomography\n",
        "\n",
        "for i in range(len(images) - 1):\n",
        "    kp1 = np.array([keypoints[i][m.queryIdx].pt for m in matches[i]])\n",
        "    kp2 = np.array([keypoints[i + 1][m.trainIdx].pt for m in matches[i]])\n",
        "\n",
        "    H, mask = cv2.findHomography(kp1, kp2, cv2.RANSAC, 4.0)\n",
        "\n",
        "    matches[i] = [m for m, msk in zip(matches[i], mask) if msk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e2bcdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot matches\n",
        "for i in range(3):\n",
        "    img_i = cv2.drawMatches(\n",
        "        images[i],\n",
        "        keypoints[i],\n",
        "        images[i + 1],\n",
        "        keypoints[i + 1],\n",
        "        matches[i],\n",
        "        None,\n",
        "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
        "    )\n",
        "\n",
        "    plt.imshow(img_i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7327ce70",
      "metadata": {},
      "source": [
        "## Step 3: Essential Matrix Estimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the best image pair with the most matches\n",
        "best_pair_idx = np.argmax([len(m) for m in matches])\n",
        "best_matches = matches[best_pair_idx]\n",
        "print(f\"Best pair: {best_pair_idx} -> {best_pair_idx + 1}\")\n",
        "\n",
        "# Get points from matches\n",
        "pts1 = np.float32([keypoints[best_pair_idx][m.queryIdx].pt for m in best_matches])\n",
        "pts2 = np.float32([keypoints[best_pair_idx + 1][m.trainIdx].pt for m in best_matches])\n",
        "\n",
        "# Compute the essential matrix\n",
        "K = np.array(\n",
        "    [\n",
        "        [1698.873755, 0.000000, 971.7497705],\n",
        "        [0.000000, 1698.8796645, 647.7488275],\n",
        "        [0.000000, 0.000000, 1.000000],\n",
        "    ]\n",
        ")\n",
        "E, mask = cv2.findEssentialMat(\n",
        "    pts1, pts2, K, method=cv2.RANSAC, prob=0.999, threshold=1.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db00bf73",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_outliers = np.sum(mask == 0)\n",
        "print(f\"Number of outliers: {num_outliers}\")\n",
        "\n",
        "num_inliers = np.sum(mask == 1)\n",
        "print(f\"Number of inliers: {num_inliers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Camera Pose Estimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9803ef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "R1, R2, t = cv2.decomposeEssentialMat(E)\n",
        "\n",
        "# Select the correct rotation and translation\n",
        "P1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
        "P2s = [\n",
        "    np.hstack((R1, t)),\n",
        "    np.hstack((R1, -t)),\n",
        "    np.hstack((R2, t)),\n",
        "    np.hstack((R2, -t)),\n",
        "]\n",
        "\n",
        "# Triangulate points\n",
        "points = cv2.triangulatePoints(K @ P1, K @ P2s[0], pts1.T, pts2.T)\n",
        "points /= points[3]\n",
        "\n",
        "# Select the correct P2\n",
        "P2 = None\n",
        "for P2_i in P2s:\n",
        "    points_i = cv2.triangulatePoints(K @ P1, K @ P2_i, pts1.T, pts2.T)\n",
        "    points_i /= points_i[3]\n",
        "    if np.all(points_i[2] > 0):\n",
        "        P2 = P2_i\n",
        "        points = points_i\n",
        "        break\n",
        "\n",
        "print(\"R:\", P2[:, :3])\n",
        "print(\"t:\", P2[:, 3])\n",
        "\n",
        "# Double check the results\n",
        "_, R_, t_, mask = cv2.recoverPose(E, pts1, pts2, K)\n",
        "print(f\"{np.allclose(R_, P2[:, :3])=}\")\n",
        "print(f\"{np.allclose(t_.T, P2[:, 3])=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad0ba67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reconstruct 3D points using cv2.triangulatePoints\n",
        "points = cv2.triangulatePoints(K @ P1, K @ P2, pts1.T, pts2.T)\n",
        "points /= points[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d293d4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "\n",
        "cloud = o3d.geometry.PointCloud()\n",
        "cloud.points = o3d.utility.Vector3dVector(points.T[:, :3])\n",
        "\n",
        "o3d.io.write_point_cloud(f\"{data_out}/{data_set}-2.ply\", cloud)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
